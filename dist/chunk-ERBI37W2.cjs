'use strict';

var chunk57AVKP4H_cjs = require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');
var ffmpeg = require('@ffmpeg/ffmpeg');

var we={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0,ffmpegCoreURL:chunk57AVKP4H_cjs.b},ye={stop:void 0},z={blob:void 0,text:void 0},ke=N=>{let{apiKey:b,autoStart:v,autoTranscribe:U,mode:S,nonStop:A,removeSilence:x,stopTimeout:G,streaming:T,timeSlice:J,whisperConfig:u,onDataAvailable:Q,onTranscribe:l,ffmpegCoreURL:V}={...we,...N};if(!b&&!l)throw new Error("apiKey is required if onTranscribe is not provided");let m=react.useRef([]),i=react.useRef(),s=react.useRef(),t=react.useRef(),a=react.useRef(),g=react.useRef(ye),[X,R]=react.useState(!1),[Y,B]=react.useState(!1),[Z,p]=react.useState(!1),[W,w]=react.useState(z),[ee,E]=react.useState(!1),D=react.useRef(),[H,k]=react.useState(!1),re=async()=>{let e=ffmpeg.createFFmpeg({mainName:"main",corePath:V,log:!0});D.current=e,e.isLoaded()||await e.load(),k(!0);};react.useEffect(()=>()=>{m.current&&(m.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),h("stop"),s.current&&(s.current.off("speaking",F),s.current.off("stopped_speaking",C)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{v&&await L();},[v]);let te=async()=>{await L();},ne=async()=>{await ue();},oe=async()=>{await P();},ae=async()=>{await M();},ie=()=>{E(!1);},se=()=>{w(z);},L=async()=>{try{if(!H&&x&&re(),a.current||await ce(),!i.current){let{Mp3Encoder:e}=await import('lamejs');i.current=new e(1,44100,96);}if(a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:T?J:void 0,type:"audio",ondataavailable:U&&T?pe:void 0};t.current=new r(a.current,n);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),A&&_("stop"),R(!0);}}catch(e){console.error(e);}},ce=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",F),s.current.on("stopped_speaking",C);}}catch(e){console.error(e);}},_=e=>{g.current[e]||(g.current[e]=setTimeout(P,G));},F=()=>{console.log("start speaking"),B(!0),h("stop");},C=()=>{console.log("stop speaking"),B(!1),A&&_("stop");},ue=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),h("stop"),R(!1));}catch(e){console.error(e);}},P=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),fe(),h("stop"),R(!1),U)await M();else {let r=await t.current.getBlob();w({blob:r});}await t.current.destroy(),m.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch(e){console.error(e);}},fe=()=>{s.current&&(s.current.off("speaking",F),s.current.off("stopped_speaking",C),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},h=e=>{g.current[e]&&(clearTimeout(g.current[e]),g.current[e]=void 0);},I=async e=>{let r;if(typeof l=="function"){let{text:o}=await l(e);r=o;}else {let o=new File([e],"speech.mp3",{type:"audio/mpeg"});r=await q(o);}console.log("onTranscribe",{result:r}),w({blob:e,text:r}),E(r===void 0);},M=async()=>{console.log("transcribing speech");try{if(i.current&&t.current){if(await t.current.getState()==="stopped"){p(!0);let r=await t.current.getBlob();if(x&&H){let o=await r.arrayBuffer();console.log({in:o.byteLength});let n=D.current;if(n){n.FS("writeFile","in.wav",new Uint8Array(o)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunk57AVKP4H_cjs.c,"out.mp3");let y=n.FS("readFile","out.mp3");if(console.log({out:y.buffer.byteLength}),y.length<=358){n.exit(),k(!1),w({blob:r}),p(!1);return}r=new Blob([y.buffer],{type:"audio/mpeg"}),n.exit(),k(!1);}}else {let o=await r.arrayBuffer();console.log({wav:o.byteLength});let n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"}),console.log({blob:r,mp3:n.byteLength});}await I(r),p(!1);}}else {let{blob:e}=W;e&&(p(!0),await I(e),p(!1));}}catch(e){console.info(e),p(!1);}},pe=async e=>{console.log("onDataAvailable",e);try{if(T&&t.current){if(Q?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),c=new Blob([n],{type:"audio/mpeg"});m.current.push(c);}if(await t.current.getState()==="recording"){let o=new Blob(m.current,{type:"audio/mpeg"}),n;if(typeof l=="function"){let{text:c}=await l(o);n=c;}else {let c=new File([o],"speech.mp3",{type:"audio/mpeg"});n=await q(c);}console.log("onInterim",{result:n}),n&&w(c=>({...c,text:n}));}}}catch(r){console.error(r);}},q=reactHooksAsync.useMemoAsync(async e=>{let r=new FormData;r.append("file",e),r.append("model","whisper-1"),S==="transcriptions"&&r.append("language",u?.language??"en"),u?.prompt&&r.append("prompt",u.prompt),u?.response_format&&r.append("response_format",u.response_format),u?.temperature&&r.append("temperature",`${u.temperature}`);let o={};o["Content-Type"]="multipart/form-data",b&&(o.Authorization=`Bearer ${b}`);let{default:n}=await import('axios'),{default:c}=await import('axios-retry');c(n,{retries:3,retryDelay:c.exponentialDelay});try{return (await n.post(chunk57AVKP4H_cjs.d+S,r,{headers:o})).data.text}catch{return}},[b,S,u]);return {recording:X,speaking:Y,transcribing:Z,transcript:W,isTranscribingError:ee,pauseRecording:ne,startRecording:te,stopRecording:oe,startTranscribing:ae,clearTranscribingError:ie,clearTranscript:se}};

exports.a = ke;
