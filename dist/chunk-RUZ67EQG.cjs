'use strict';

var chunkG7VPYZGL_cjs = require('./chunk-G7VPYZGL.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var pe={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0,ffmpegURL:"/"},de={stop:void 0},le={blob:void 0,text:void 0},be=q=>{let{apiKey:b,autoStart:A,autoTranscribe:C,mode:T,nonStop:F,removeSilence:K,stopTimeout:O,streaming:S,timeSlice:z,whisperConfig:u,onDataAvailable:G,onTranscribe:R,ffmpegURL:y}={...pe,...q};if(!b&&!R)throw new Error("apiKey is required if onTranscribe is not provided");let m=react.useRef([]),i=react.useRef(),s=react.useRef(),t=react.useRef(),a=react.useRef(),g=react.useRef(de),[J,k]=react.useState(!1),[N,B]=react.useState(!1),[Q,p]=react.useState(!1),[x,w]=react.useState(le),[V,X]=react.useState(!1),W=react.useRef(),[L,Y]=react.useState(!1),Z=async()=>{let e={workerURL:`${y}814.ffmpeg.js`,coreURL:`${y}ffmpeg-core.js`,wasmURL:`${y}ffmpeg-core.wasm`};import(`${y}ffmpeg.js`).then(async o=>{let n=new o.FFmpeg;W.current=n,n.on("log",({message:c})=>{}),await n.load(e),Y(!0);});};react.useEffect(()=>()=>{m.current&&(m.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),h("stop"),s.current&&(s.current.off("speaking",U),s.current.off("stopped_speaking",v)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{A&&await E();},[A]);let ee=async()=>{await E();},re=async()=>{await ae();},te=async()=>{await H();},ne=async()=>{await M();},E=async()=>{try{if(L||Z(),a.current||await oe(),a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:S?z:void 0,type:"audio",ondataavailable:C&&S?se:void 0};t.current=new r(a.current,n);}if(!i.current){let{Mp3Encoder:r}=await import('lamejs');i.current=new r(1,44100,96);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),F&&D("stop"),k(!0);}}catch{}},oe=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",U),s.current.on("stopped_speaking",v);}}catch{}},D=e=>{g.current[e]||(g.current[e]=setTimeout(H,O));},U=()=>{B(!0),h("stop");},v=()=>{B(!1),F&&D("stop");},ae=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),h("stop"),k(!1));}catch{}},H=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),ie(),h("stop"),k(!1),C)await M();else {let r=await t.current.getBlob();w({blob:r});}await t.current.destroy(),m.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch{}},ie=()=>{s.current&&(s.current.off("speaking",U),s.current.off("stopped_speaking",v),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},h=e=>{g.current[e]&&(clearTimeout(g.current[e]),g.current[e]=void 0);},_=async e=>{if(typeof R=="function"){let r=await R(e);w(r);}else {let r=new File([e],"speech.mp3",{type:"audio/mpeg"}),o=await $(r);w({blob:e,text:o}),o===void 0&&X(!0);}},M=async()=>{try{if(i.current&&t.current){if(await t.current.getState()==="stopped"){p(!0);let r=await t.current.getBlob();if(K&&L){let o=await r.arrayBuffer(),n=W.current;if(n){await n.writeFile("in.wav",new Uint8Array(o)),await n.exec(["-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunkG7VPYZGL_cjs.b,"out.mp3"]);let d=await n.readFile("out.mp3");if(d.length<=358){w({blob:r}),p(!1);return}r=new Blob([d.buffer],{type:"audio/mpeg"});}}else {let o=await r.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"});}await _(r),p(!1);}}else {let{blob:e}=x;e&&(p(!0),await _(e),p(!1));}}catch{p(!1);}},se=async e=>{try{if(S&&t.current){if(G?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),c=new Blob([n],{type:"audio/mpeg"});m.current.push(c);}if(await t.current.getState()==="recording"){let o=new Blob(m.current,{type:"audio/mpeg"}),n=new File([o],"speech.mp3",{type:"audio/mpeg"}),c=await $(n);c&&w(d=>({...d,text:c}));}}}catch{}},$=reactHooksAsync.useMemoAsync(async e=>{let r=new FormData;r.append("file",e),r.append("model","whisper-1"),T==="transcriptions"&&r.append("language",u?.language??"en"),u?.prompt&&r.append("prompt",u.prompt),u?.response_format&&r.append("response_format",u.response_format),u?.temperature&&r.append("temperature",`${u.temperature}`);let o={};o["Content-Type"]="multipart/form-data",b&&(o.Authorization=`Bearer ${b}`);let{default:n}=await import('axios'),{default:c}=await import('axios-retry');c(n,{retries:3,retryDelay:c.exponentialDelay});try{return (await n.post(chunkG7VPYZGL_cjs.c+T,r,{headers:o})).data.text}catch{return}},[b,T,u]);return {recording:J,speaking:N,transcribing:Q,transcript:x,isTranscribingError:V,pauseRecording:re,startRecording:ee,stopRecording:te,startTranscribing:ne}};

exports.a = be;
