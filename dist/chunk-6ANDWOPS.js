import { c, d, b } from './chunk-VO7VPLVP.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';
import { createFFmpeg } from '@ffmpeg/ffmpeg';

var we={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0,ffmpegCoreURL:b},ye={stop:void 0},J={blob:void 0,text:void 0},Fe=Q=>{let{apiKey:y,autoStart:U,autoTranscribe:A,mode:T,nonStop:x,removeSilence:B,stopTimeout:V,streaming:k,timeSlice:X,whisperConfig:f,onDataAvailable:Y,onTranscribe:m,ffmpegCoreURL:Z}={...we,...Q};if(!y&&!m)throw new Error("apiKey is required if onTranscribe is not provided");let g=useRef([]),i=useRef(),s=useRef(),t=useRef(),a=useRef(),b=useRef(ye),[ee,R]=useState(!1),[h,W]=useState(!1),E=useRef(h),[re,d$1]=useState(!1),[D,w]=useState(J),[te,H]=useState(!1);useEffect(()=>{E.current=h;},[h]);let L=useRef(),[_,F]=useState(!1),ne=async()=>{let e=createFFmpeg({mainName:"main",corePath:Z,log:!0});L.current=e,e.isLoaded()||await e.load(),F(!0);};useEffect(()=>()=>{g.current&&(g.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),S("stop"),s.current&&(s.current.off("speaking",C),s.current.off("stopped_speaking",v)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),useEffectAsync(async()=>{U&&await P();},[U]);let oe=async()=>{await P();},ae=async()=>{await pe();},ie=async()=>{await M();},se=async()=>{await K();},ce=()=>{H(!1);},ue=()=>{w(J);},P=async()=>{try{if(!_&&B&&ne(),a.current||await fe(),!i.current){let{Mp3Encoder:e}=await import('lamejs');i.current=new e(1,44100,96);}if(a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:k?X:void 0,type:"audio",ondataavailable:A&&k?le:void 0};t.current=new r(a.current,n);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),x&&I("stop"),R(!0);}}catch{}},fe=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",C),s.current.on("stopped_speaking",v);}}catch{}},I=e=>{b.current[e]||(b.current[e]=setTimeout(M,V));},C=()=>{W(!0),S("stop");},v=()=>{W(!1),x&&I("stop");},pe=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),S("stop"),R(!1));}catch{}},M=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),de(),S("stop"),R(!1),A)await K();else {let r=await t.current.getBlob();w({blob:r});}await t.current.destroy(),g.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch{}},de=()=>{s.current&&(s.current.off("speaking",C),s.current.off("stopped_speaking",v),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},S=e=>{b.current[e]&&(clearTimeout(b.current[e]),b.current[e]=void 0);},q=async e=>{let r;if(typeof m=="function"){let{text:o}=await m(e);r=o;}else {let o=new File([e],"speech.mp3",{type:"audio/mpeg"});r=await O(o);}w({blob:e,text:r}),H(r===void 0);},K=async()=>{try{if(i.current&&t.current){if(await t.current.getState()==="stopped"){d$1(!0);let r=await t.current.getBlob();if(B&&_){let o=await r.arrayBuffer(),n=L.current;if(n){n.FS("writeFile","in.wav",new Uint8Array(o)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",c,"out.mp3");let c$1=n.FS("readFile","out.mp3");if(c$1.length<=358){n.exit(),F(!1),w({blob:r}),d$1(!1);return}r=new Blob([c$1.buffer],{type:"audio/mpeg"}),n.exit(),F(!1);}}else {let o=await r.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"});}await q(r),d$1(!1);}}else {let{blob:e}=D;e&&(d$1(!0),await q(e),d$1(!1));}}catch{d$1(!1);}},le=async e=>{try{let r=typeof s.current?.stop=="function"?E.current:!0;if(k&&t.current&&r){if(Y?.(e),i.current){let n=await e.arrayBuffer(),u=i.current.encodeBuffer(new Int16Array(n)),c=new Blob([u],{type:"audio/mpeg"});g.current.push(c);}if(await t.current.getState()==="recording"){let n=new Blob(g.current,{type:"audio/mpeg"}),u;if(typeof m=="function"){let{text:c}=await m(n);u=c;}else {let c=new File([n],"speech.mp3",{type:"audio/mpeg"});u=await O(c);}u&&w(c=>({...c,text:u}));}}}catch{}},O=useMemoAsync(async e=>{let r=new FormData;r.append("file",e),r.append("model","whisper-1"),T==="transcriptions"&&r.append("language",f?.language??"en"),f?.prompt&&r.append("prompt",f.prompt),f?.response_format&&r.append("response_format",f.response_format),f?.temperature&&r.append("temperature",`${f.temperature}`);let o={};o["Content-Type"]="multipart/form-data",y&&(o.Authorization=`Bearer ${y}`);let{default:n}=await import('axios'),{default:u}=await import('axios-retry');u(n,{retries:3,retryDelay:u.exponentialDelay});try{return (await n.post(d+T,r,{headers:o})).data.text}catch{return}},[y,T,f]);return {recording:ee,speaking:h,transcribing:re,transcript:D,isTranscribingError:te,pauseRecording:ae,startRecording:oe,stopRecording:ie,startTranscribing:se,clearTranscribingError:ce,clearTranscript:ue}};

export { Fe as a };
