import { c, d, b } from './chunk-VO7VPLVP.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';
import { createFFmpeg } from '@ffmpeg/ffmpeg';

var le={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0,ffmpegCoreURL:b},me={stop:void 0},ge={blob:void 0,text:void 0},Te=j=>{let{apiKey:w,autoStart:v,autoTranscribe:U,mode:h,nonStop:A,removeSilence:z,stopTimeout:N,streaming:S,timeSlice:G,whisperConfig:c$1,onDataAvailable:J,onTranscribe:T,ffmpegCoreURL:Q}={...le,...j};if(!w&&!T)throw new Error("apiKey is required if onTranscribe is not provided");let m=useRef([]),i=useRef(),s=useRef(),t=useRef(),a=useRef(),g=useRef(me),[V,R]=useState(!1),[X,x]=useState(!1),[Y,p]=useState(!1),[B,b]=useState(ge),[Z,W]=useState(!1),E=useRef(),[D,k]=useState(!1),ee=async()=>{let e=createFFmpeg({mainName:"main",corePath:Q,log:!0});E.current=e,e.isLoaded()||await e.load(),k(!0);};useEffect(()=>()=>{m.current&&(m.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),y("stop"),s.current&&(s.current.off("speaking",F),s.current.off("stopped_speaking",C)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),useEffectAsync(async()=>{v&&await H();},[v]);let re=async()=>{await H();},te=async()=>{await ie();},ne=async()=>{await _();},oe=async()=>{await I();},H=async()=>{try{if(D||ee(),a.current||await ae(),a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:S?G:void 0,type:"audio",ondataavailable:U&&S?ce:void 0};t.current=new r(a.current,n);}if(!i.current){let{Mp3Encoder:r}=await import('lamejs');i.current=new r(1,44100,96);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),A&&L("stop"),R(!0);}}catch{}},ae=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",F),s.current.on("stopped_speaking",C);}}catch{}},L=e=>{g.current[e]||(g.current[e]=setTimeout(_,N));},F=()=>{x(!0),y("stop");},C=()=>{x(!1),A&&L("stop");},ie=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),y("stop"),R(!1));}catch{}},_=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),se(),y("stop"),R(!1),U)await I();else {let r=await t.current.getBlob();b({blob:r});}await t.current.destroy(),m.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch{}},se=()=>{s.current&&(s.current.off("speaking",F),s.current.off("stopped_speaking",C),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},y=e=>{g.current[e]&&(clearTimeout(g.current[e]),g.current[e]=void 0);},P=async e=>{if(typeof T=="function"){let r=await T(e);b(r);}else {let r=new File([e],"speech.mp3",{type:"audio/mpeg"}),o=await M(r);b({blob:e,text:o}),W(o===void 0);}},I=async()=>{try{if(i.current&&t.current){if(await t.current.getState()==="stopped"){p(!0);let r=await t.current.getBlob();if(z&&D){let o=await r.arrayBuffer(),n=E.current;if(n){n.FS("writeFile","in.wav",new Uint8Array(o)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",c,"out.mp3");let d=n.FS("readFile","out.mp3");if(d.length<=358){n.exit(),k(!1),b({blob:r}),p(!1);return}r=new Blob([d.buffer],{type:"audio/mpeg"}),n.exit(),k(!1);}}else {let o=await r.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"});}await P(r),p(!1);}}else {let{blob:e}=B;e&&(p(!0),await P(e),p(!1));}}catch{p(!1);}},ce=async e=>{try{if(S&&t.current){if(J?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),u=new Blob([n],{type:"audio/mpeg"});m.current.push(u);}if(await t.current.getState()==="recording"){let o=new Blob(m.current,{type:"audio/mpeg"}),n=new File([o],"speech.mp3",{type:"audio/mpeg"}),u=await M(n);u&&b(d=>({...d,text:u}));}}}catch{}},M=useMemoAsync(async e=>{let r=new FormData;r.append("file",e),r.append("model","whisper-1"),h==="transcriptions"&&r.append("language",c$1?.language??"en"),c$1?.prompt&&r.append("prompt",c$1.prompt),c$1?.response_format&&r.append("response_format",c$1.response_format),c$1?.temperature&&r.append("temperature",`${c$1.temperature}`);let o={};o["Content-Type"]="multipart/form-data",w&&(o.Authorization=`Bearer ${w}`);let{default:n}=await import('axios'),{default:u}=await import('axios-retry');u(n,{retries:3,retryDelay:u.exponentialDelay});try{return (await n.post(d+h,r,{headers:o})).data.text}catch{return}},[w,h,c$1]);return {recording:V,speaking:X,transcribing:Y,transcript:B,isTranscribingError:Z,pauseRecording:te,startRecording:re,stopRecording:ne,startTranscribing:oe}};

export { Te as a };
